<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Shared Autonomy Ritika Ghosh</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Ritika Ghosh</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li class="active"><a href="SharedAutonomy.html">Shared Autonomy</a></li>
                            <li><a href="Resume.html">Resume</a></li>
                            <li><a href="AboutMe.html">About Me</a></li>
						</ul>
						<ul class="icons">
							<li><a href="mailto:ritikaghosh2023@u.northwestern.edu" class="icon web application fa-envelope"><span class="label">Email</span></a></li>
							<li><a href="https://linkedin.com/in/Ritika-Ghosh" class="icon brands fa-linkedin"><span class="label">Linkedln</span></a></li>
							<li><a href="https://github.com/GhoshRitika" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<h1> <a href="https://github.com/GhoshRitika/Allegro_hand">Shared Autonomy with Reinforcement Learning</a></h1>
								</header>
                  <video width="100%" height="100%" autoplay loop muted>
                      <source src="images/SharedAutonomy.mp4" type="video/mp4">
                      <source src="SharedAutonomy.ogg" type="video/ogg">
                  </video>
                  <div class="box alt"></div>
								<header>
									<h2>Overview</h2>
									</header>
									<p>This project allows for human robot collaboration with the help of an assistive agent which minimally adjusts the human actions to improve the task performance without any prior knowledge or restrictive assumptions about the environment, goal space or human policy. This is an adaptation of model free
                                        constrained residual policy using proximal policy optimization for shared control. It has been tested on Lunar Lander and Franka Reach environments.</p>
                                    <p>Here a joystick is used to interact with the environment, the human uses the joystick to get the human actions and the constrained residual policy provides the assistive actions, a combination of both acts as the actual action that the environment receives.</p>
									<hr />

								<!-- Lists -->
									<h2>Data Pipeline and Neural Network Architecture</h2>
                                    <a href="#" class="image fit"><img src="images/Datapipeline.png" alt="" /></a>
									<div class="row">
										<div class="col-6 col-12-small">
                                            <p>The bahavioral cloning agent is a 3 layer neural network with 128 hidden units each, is trained with data collected from human playing in the environment to act as the surragate human policy Ï€_h. The assistive agent is also a 3 layer neural network with 128 hidden units per layer
                                                and 2 heads, one for the policy and other for the value function. This copilot policy implements a version of constrained proximal policy optimization with the residual learning algorithm. Learn more about this algorithm <a href="https://arxiv.org/pdf/2004.05097.pdf">here</a>
                                            </p>
                                        </div>

                                        <div class="col-6 col-12-small">
                                            <a href="#" class="image fit"><img src="images/AlgorithmRL.png" alt="" /></a>
                                        </div>
                                        <p>The above datapipeline shows how the human surrogate along with the state of the environment is as an input to the copilot policy which results in the assistive action.</p>
                                    </div>
                                    <h2>Lunar Lander</h2>
									<div class="row">
										<div class="col-6 col-12-small">
                                            <p>The goal of the lunar lander game is to land the spaceship inbetween the flags using its 3 thrusters to control its motion. It has a 2 dimensional action space and an 8 dimensional observation space in the continuous environment. The human surrogate policy trains over 80 episodes and the residual policy is trained over 10,000 episodes resulting in assistive actions that significantly improve the results.</p>
                                        </div>
                                        <div class="col-6 col-12-small">
                                            <a href="#" class="image fit">
                                                <video width="100%" height="100%" autoplay loop muted>
                                                    <source src="images/LunarLanderAss (2).mp4" type="video/mp4">
                                                    <source src="LunarLanderAss (2).ogg" type="video/ogg">
                                                </video>
                                            </a>
                                        </div>
                                    </div>
                                    <hr />
									<h2>Franka Panda</h2>
									<div class="col">
                                        <div class="row-6 row-12-small">
                                            <a href="#" class="image fit">
                                                <video width="100%" height="100%" autoplay loop muted>
                                                    <source src="images/FrankaReachwAss.mp4" type="video/mp4">
                                                    <source src="FrankaReachwAss.ogg" type="video/ogg">
                                                </video>
                                            </a>
                                        </div>
										<div class="row-6 row-12-small">
                                            <p>The goal for the FrankaReach environment is for the end effector to reach the desired position where the reward is based in the distance from this desired goal position. This environment uses an Inverse Kinematics controller to move the end effector in the x, y and z planes, therefore has a 3 dimensional action space and a 6 dimensional observation space. In my version, the desired goal can be set by the user or be random.</p>
                                            <p> A PID controller was used as a human surrogate policy instead of the behavior cloning neural network, since training a good agent through behavioral cloning was requiring a lot of data collected from human. After training the residual policy for 10,000 epsiodes, the assistive actions were successful in improving the efficiency of reaching the goal in reducing the overall time required and the total score.</p>
                                        </div>
                                    </div>
                                    <hr />
                                    <h2>Franka with Multiple Goals</h2>
									<div class="col">
                                        <div class="row-6 row-12-small">
                                            <a href="#" class="image fit">
                                              <video width="100%" height="100%" autoplay loop muted>
                                                <source src="images/MultiGoal.mp4" type="video/mp4">
                                                <source src="MultiGoal.ogg" type="video/ogg">
                                              </video></a>
                                        </div>
										<div class="row-6 row-12-small">
                                            <p>The multi-goal FrankaReach is a new environment designed such that there are 2 goals, a red and a green one. The reward is such that the penalty for being at a distance from the green goal is double the penalty for being at a distance from the red one. The point of this experiment was to observe the behaviour of the assistive agent if the human agent tried to reach the red agent.
                                                It was observed that the assistive agent prioritized the goal that was closest to the end effector.
                                            </p>
                                        </div>
                                    </div>
                                    <hr />
									<h2>Results</h2>
									<dl>
                                        <div class="row">
                                            <div class="col-6 col-12-small">
                                                <a href="#" class="image fit"><img src="images/LLplot.png" alt="" /></a>
                                            </div>
                                            <div class="col-6 col-12-small">
                                                <a href="#" class="image fit"><img src="images/Frankaplot.png" alt="" /></a>
                                            </div>
                                        </div>
                                        <p>The above plots shows the accumulated rewards of the environment as it trained. In both the environments it is observed that the assistive agent, inspite of take very minimal actions does infact improve the humans ability to acheive the goals successfully. The total score and the time taken to reach the goal in case of the Franka Reach environment were the metrics used to ascertain the impact of the assistive agent.</p>
									</dl>

                                    <h3>Know more about this project at <a href="https://github.com/GhoshRitika/Allegro_hand">this github link</a> .</h3>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>